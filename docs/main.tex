
\documentclass[11pt,reqno]{article}

\usepackage{amscd}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{fancyhdr}
\usepackage{latexsym}
%\usepackage{hyperref}
\usepackage[colorlinks=true, pdfstartview=FitV, linkcolor=blue,
            citecolor=blue, urlcolor=blue]{hyperref} \usepackage[pdftex]{graphicx} \usepackage{epstopdf}

% Any custom macros or packages can go here
\newtheorem{remark}{Remark}

\title{\textbf{CSC-411 Assignment 1}}
\author{Anthony Ozog}
\date{\today}
\markboth{title}{A. Ozog}

\begin{document} \maketitle
% I do not feel I needed an abstract
% \begin{abstract}
  % This is the abstract
% \end{abstract}

\section*{Introduction}
  Since I am a math major I have explored most programming and software development I know outside of my studies and as a result I have never gotten to implement any of these sorting algorithms before. I really took this as an opportunity to both learn these new algorithms and practice some of the tools I like using (i.e. LaTeX, rust, R, and Test Driven Development). As a bonus I also got to see the capabilities of the rust language, which I am quite fond of, and I would say the language/compiler preformed quite well, at first I was measuring in Microsecond and I was still getting 0 results for smaller $n$'s so I switched to measuring Nanoseconds 

\section{Sorting Implementations}
% Do not forget the brief note on minor optimizations/ and design choices in the rust code
Over all the implementation was really fun but I found myself a little annoyed with the bounds checking rust imposes to maintain safety, I wish there was some way to turn it off for a whole function or module, but that is probably something that will be addressed in the future.
  \subsection{Bubble Sort} 
  I use a match statement to handle boolean for the early exit optimization, this reduces necessary rewrite of the boolean. I also sure a rust \texttt{unsafe} block to skip the bounds check when I compare elements; however, if I wanted it to be even faster I should have written my own unsafe version of swap to skip the bounds check since rust does not natively provide an unchecked swap.
  \subsection{Insertion Sort} 
  It my first implementation I used a \texttt{.clone} on a \texttt{usize} but I later remember that \texttt{usize} implements a \texttt{copy} trait which is a little faster so I came back and fixed that. Otherwise I was a standard implementation with the same bounds checking optimizations and concessions as mentioned previously.
  \subsection{Merge Sort} 
  I used an unsafe block to skip the bounds check when I split the vector. Also in my merge function I use iterators to make the merge much faster. I should be using slices instead of vectors so that it can be done without cloning but I did not implement that. Finally the same bounds checking optimizations and concessions apply here as well.

\section{Input Generation}
% Do not forget to document how the inputs are made
For any randomly generated numbers I used \href{https://docs.rs/rand/latest/rand/rngs/struct.SmallRng.html}{this} rng from the rand crate in rust.

\subsection{Uniform Random} 
I create an iterator of random numbers, take $n$ of them, and collect it into a \texttt{Vec<i64>}.
\subsection{Sorted}
I call the function to generate a Uniform Random vector of $n$ elements then I sort it using the built in sort function.
\subsection{Reverse Sorted}
I call the function to generate a Uniform Random vector of $n$ elements then I sort it using the built in sort function and then I reverse it using the built in function.
\subsection{Almost Sorted}
I call the function of generate a sorted vector of \texttt{i64} then make $\frac{n}{4}$ random swaps using the swap function and random from $0$ to $n$.
\subsection{Pipe Organ}
I call the function to generate $2$ sorted vectors of \texttt{i64} of length $\frac{n}{2}$ then I append which ever vector has the smaller maximum element to the other. I do this to ensure I am not increasing past the halfway mark.

\section{Timing}
The only thing to note about the code I used form the timing is that I used \href{https://doc.rust-lang.org/std/time/struct.Instant.html}{this} to handle the timing. I also used \texttt{clone} more than a optimized program should have but the \texttt{clone} does not affect the timing

\section{Analysis}
To note, this was both my first time implementing these sorting algorithms and my first time comparing them. None of the results surprised me aside from the tests on the sorted data.
\subsection{Running the code}
To note, 
\begin{enumerate}
  \item make sure you are in the correct directory
  \item make sure you have cargo installed
  \item the instructions to install it can be found here \href{https://doc.rust-lang.org/cargo/getting-started/installation.html}{here}
  \item make sure you have R installed as well
  \item the instructions to install it can be found \href{https://rstudio-education.github.io/hopr/starting.html}{here}
  \item make sure you have the R jsonlite library installed too
  \item run the following commands in bash if you do note have the library
    \begin{itemize}
      \item sudo R
      \item install.packages("jsonlite")
    \end{itemize}
    
\end{enumerate}

\begin{verbatim}
cargo test
cargo build -r
./target/release/CSC-411-Assignment-1
# or however you would run a binary on the operating system of your choice
# next I make a fresh dir and run the 2 R scripts on the new data
mkdir test
mv optimized_results.json test/
mv deg_space_results.json test/
cp /graphs/graph_building.r test/
cp /graphs/deg_graph_building.r test/
cd test
Rscript graph_building.r
Rscript deg_graph_building.r
\end{verbatim}

\subsection{Bubble and Insertion Sort Comparison}
% Bubble is slower but they have the same complexity
For random inputs Bubble Sort is much slower than Insertion Sort. I know that they have the same complexity but Bubble Sort preforms more swaps and comparisons so even though the theoretical complexity is the same among the two sorting algorithms Insertion sort is much faster. To this point at $n=10,000$ Bubble Sort took $63,839,181$ Nanoseconds while Insertion Sort took $8,963,227$ Nanoseconds, $\times 8$ faster.
\subsection{Benefits of nearly sorted inputs}
% Insertion sort benefits the most
The percent faster for each algorithm at $n=10,000$ as compared to the Uniform Random data is as follows
\begin{description}
  \item[Bubble Sort] $\% 31.94$
  \item[Insertion Sort] $\%  49.79$
  \item[Merge Sort] $\% 12.43$
\end{description}
So as the data describes, Insertion Sort benefits the most followed by Bubble Sort. This makes since both of these algorithms take an iterative approach where as merge does not get to benefit from the nicer data since it still has to break it down and piece it back together. Insertion Sort benefits the most since it is building the section of sorted data and that becomes very easy since the data is input in a nice way.

\subsection{Input size and Merge Sort}
% Go look at the graphs 
I would say around $n = 4,000$ Merge Sort becomes the clear winner.
\subsection{Early-exit Bubble Sort}
% Does super well on the Sorted and much better on the nearly sorted data
With the implementation of early exit optimization Bubble sort preforms at a $\% 31$ increase in efficiency on nearly sorted data, as mentioned previously. I also only takes $6134$ nanoseconds on average to finish executing on the sorted data where $n=10,000$. This early exit makes it much faster than even merge sort is on the sorted data.
\subsection{Theory vs. Experiment}
% Load times and added operations from some of the abstractions
The biggest difference I noticed in between the theory and the experiment came from how operations are actually done on the machine. One expression of this can be seen in the previously section discussing how Bubble Sort and Insertion Sort have the same computational complexity but their actual execution was very different. A second example is the problem that was plaguing me during my implementation, the bounds checking. I was comparing my execution times with Joe Sypal, who wrote his solutions in \texttt{C}. Rust, even though it is built on the same back end (LLVM), was coming in a bit slower because of the bounds checks I failed to remove. Also, comparing these solutions across languages shows best this idea of how different the operations are actually being preformed. All these algorithms are the same, with the same time and space complexity but when running the experiment the outcome can go very differently because of what is actually happening on the machine.

\section{Degraded Spatial Locality}
For this part of the assignment I took all of my clean and simple \texttt{fn(Vec<i64>) -> Vec<i64>} functions and gave them an "evil" twin implementation. I made functions of the following type: \texttt{fn(Vec<Ising>) -> Vec<Ising>}. All I did was create a wrapper struct around the \texttt{i64} and put those into vectors. In doing this I took away rust ability to keep the data highly localized by both making the data larger and preventing the data from beings stored sequentially. This, for the most part, made the execution times worse across the board. In particular, Insertion Sort and Bubble Sort where affected much more than Merge Sort because of the number of comparisons and swaps they preform.  The most affected of those two was Bubble Sort, because as mentioned in a previous section, it preforms even more swaps and comparisons than Insertion Sort does.


\end{document}
       
